{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0e0d0e91",
   "metadata": {},
   "source": [
    "# Import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "149307c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ROOT\n",
    "from array import array\n",
    "import optparse\n",
    "import numba as nb\n",
    "import awkward as ak\n",
    "import vector\n",
    "import numpy as np\n",
    "from torch import nn\n",
    "from itertools import combinations, permutations\n",
    "import uproot\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "import h5py\n",
    "import os, time, argparse, matplotlib, sklearn, torch, torchmetrics\n",
    "#matplotlib.use('Agg') # Fix for $> _tkinter.TclError: couldn't connect to display \"localhost:36.0\"\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.utils import class_weight\n",
    "from sklearn.metrics import precision_recall_curve, roc_curve\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from torchmetrics import PrecisionRecallCurve, Accuracy, Precision, Recall, ROC\n",
    "\n",
    "skimstore_place = \"skim_root/\"\n",
    "h5py_place      = \"dataframe/\"\n",
    "output_place    = \"MergeOutput/\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "562dfef0",
   "metadata": {},
   "source": [
    "## Class: Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "09c4e53b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class custom_train_dataset(Dataset):\n",
    "    def __init__(self, df, input_columns, target_column, transform=None, target_transform=None, device='cpu'):\n",
    "        self.df = df\n",
    "        # make tensors for values of inputs and relveant labels\n",
    "        source_combs = self.df[input_columns].values\n",
    "        target_labels = self.df[target_column].values\n",
    "        self.x_train = torch.tensor(source_combs,dtype=torch.float32, device=torch.device(device))\n",
    "        self.y_train = torch.tensor(target_labels,dtype=torch.float32, device=torch.device(device))\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        x_ = self.x_train[index]\n",
    "        y_ = self.y_train[index]\n",
    "\n",
    "        if self.transform:\n",
    "            x_ = self.transform(x_)\n",
    "\n",
    "        return x_, y_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ecec9c6",
   "metadata": {},
   "source": [
    "## Class: Neural Network structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9aee2669",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self,nvars):\n",
    "        # return a temporary object of superclass so we can call superclass' methods\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        # Initialise layers\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Flatten(), #Flattens contiguous range of dimensions into a tensor\n",
    "            nn.Linear(nvars,24),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(24,12),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(12,8),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(8,4),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(4,1),\n",
    "        )\n",
    "    # Method to implement operations on input data\n",
    "    # Passing input data to model automatically executes models forward method\n",
    "    def forward(self, x):\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6034db71",
   "metadata": {},
   "source": [
    "## Parameter setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e9eab252",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device cuda\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "fin_name = 'ttc_a_200-700GeV_with_geninfo'\n",
    "print('device',device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe6e8db1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9d888c12",
   "metadata": {},
   "source": [
    "## Reading dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e90d0772",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = []\n",
    "\n",
    "# Scan target file\n",
    "FileList = os.listdir(h5py_place)\n",
    "for f in FileList:\n",
    "    if (fin_name in f and 'h5' in f):\n",
    "        df_ = pd.read_hdf(os.path.join(h5py_place,f))\n",
    "        df.append(df_)\n",
    "# Prepare dataframe\n",
    "df = pd.concat(df)\n",
    "\n",
    "# Data Preprocessing\n",
    "colnames = list(df.keys())\n",
    "ct = ColumnTransformer(\n",
    " [('StandardScaler', StandardScaler(), colnames[5:-3] )],\n",
    "      remainder='drop'# Drop nontransformed columns\n",
    "  )\n",
    "index_ = df[colnames[:5]]\n",
    "label_ = df[colnames[-3]]\n",
    "label_pair_ = df[colnames[-2]]\n",
    "label_valid_ = df[colnames[-1]]\n",
    "result_ = ct.fit_transform(df)\n",
    "result_ = np.c_[index_, result_, label_, label_pair_, label_valid_]\n",
    "transformed_df = pd.DataFrame(result_,columns=colnames)\n",
    "transformed_df = transformed_df.astype({'Entry':\"int\",'bmatched_jet_index':'int','lmatched_jet_index':'int','jet3_index':'int','jet4_index':'int','label':'int', 'label_pair':'int', 'label_valid':'int'})\n",
    "transformed_df.to_hdf(os.path.join(output_place,fin_name + '.h5'),'df',mode='w',format='table',data_columns=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2d1a3ba",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43ee8543",
   "metadata": {},
   "source": [
    "### Parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "566b4c05",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.00001\n",
    "batchsize = 500\n",
    "n_epochs = 450\n",
    "input_columns_ = [\n",
    "    'bmatched_jet_pt','bmatched_jet_eta','bmatched_jet_phi','bmatched_jet_mass', 'bmatched_jet_CvB', 'bmatched_jet_CvL', 'bmatched_jet_FlavB',\n",
    "    'lmatched_jet_pt','lmatched_jet_eta','lmatched_jet_phi','lmatched_jet_mass', 'lmatched_jet_CvB', 'lmatched_jet_CvL', 'lmatched_jet_FlavB',\n",
    "    'dR_bmatched_lmatched_jets','dR_bmatched_jet_lep1','dR_bmatched_jet_lep2','dR_lmatched_jet_lep1','dR_lmatched_jet_lep2',\n",
    "    'invmass_bjlj',\n",
    "    'lep1_pt','lep1_eta','lep1_phi','lep1_mass',\n",
    "    'lep2_pt','lep2_eta','lep2_phi','lep2_mass',\n",
    "    'jet3_pt','jet3_eta','jet3_phi','jet3_mass', 'jet3_CvB', 'jet3_CvL', 'jet3_FlavB',\n",
    "    'jet4_pt','jet4_eta','jet4_phi','jet4_mass', 'jet4_CvB', 'jet4_CvL', 'jet4_FlavB'    \n",
    "  ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9619ca17",
   "metadata": {},
   "source": [
    "### Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "9adb1daa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    # Set (averaged batch loss * batch size) to 0\n",
    "    batch_loss = 0.0\n",
    "    # For each batch in the dataloader\n",
    "    for batch, (X,y) in enumerate(dataloader):\n",
    "        # Set any learned gradients for optimised tensors to zero (as they will otherwise be from previous batch using different parameters)\n",
    "        optimizer.zero_grad()\n",
    "        # Alter dimensions of labels tensor\n",
    "        y = y.unsqueeze(1)\n",
    "        # Compute prediction and loss for the whole batch\n",
    "        logits = model(X)\n",
    "        # Loss computation for the batch\n",
    "        loss = loss_fn(logits, y)\n",
    "        ### Backpropagation ###\n",
    "        # compute sum of gradients of given tensor for this batch\n",
    "        loss.backward()\n",
    "        # Update weights\n",
    "        optimizer.step()\n",
    "        # Add loss to batch loss\n",
    "        batch_loss += loss.item() * X.size(0)\n",
    "        # Report every X batches\n",
    "        if batch % 10 == 0:\n",
    "            loss, current = loss.item(), batch*len(X)\n",
    "        #    print(f'loss:{loss:.4} [{current}/{size}]')\n",
    "    # Return: averaged batch loss * batch size , model\n",
    "    return batch_loss, model\n",
    "\n",
    "def test_loop(dataloader, model, loss_fn):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    batch_loss = 0.0\n",
    "    # gradient calculation disabled (not needed in evaluation)\n",
    "    with torch.no_grad():\n",
    "        # for each batch\n",
    "        for X,y in dataloader:\n",
    "            # make prediction using model\n",
    "            logits = model(X)\n",
    "            y = y.unsqueeze(1) # required to ensure same dimensions\n",
    "            # add loss for example to batch loss using prediction and ground truth\n",
    "            test_loss = loss_fn(logits, y)\n",
    "            # Add loss to batch loss\n",
    "            batch_loss += test_loss.item() * X.size(0)\n",
    "            # Report every X batches\n",
    "            #if batch % 10 == 0:\n",
    "            #    loss, current = test_loss.item(), batch*len(X)\n",
    "            #    print(f'test_loss:{test_loss:.4} [{current}/{size}]')\n",
    "\n",
    "        return batch_loss\n",
    "\n",
    "def eval_loop(dataloader, model, loss_fn):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    test_loss, correct = 0,0\n",
    "    # gradient calculation disabled (not needed in evaluation)\n",
    "    with torch.no_grad():\n",
    "        #pr_curve = PrecisionRecallCurve(pos_label=1)\n",
    "        #roc = ROC(pos_label=1)\n",
    "        all_truth_labels = []\n",
    "        all_predictions = []\n",
    "\n",
    "        # for each batch\n",
    "        for X,y in dataloader:\n",
    "            # make prediction using model\n",
    "            logits = model(X)\n",
    "            y = y.unsqueeze(1) # required to ensure same dimensions\n",
    "            all_truth_labels += y.tolist()\n",
    "            all_predictions += torch.sigmoid(logits).tolist()\n",
    "            # add loss for example to batch loss using prediction and ground truth\n",
    "            test_loss += loss_fn(logits, y).item()\n",
    "            # pair predictions with data truth\n",
    "            test_stack = torch.stack((torch.sigmoid(logits), y), dim=1)\n",
    "\n",
    "        #print('New event\\n',list(zip(all_predictions,all_truth_labels)))\n",
    "        # Look for combination with highest prediciton score\n",
    "        max_pred_ = max(all_predictions)\n",
    "        # get the index of this combination\n",
    "        max_pred_index_ = all_predictions.index(max_pred_)\n",
    "        # Look for combination with highest truth label (i.e. == 1)\n",
    "        max_truth_ = max(all_truth_labels)\n",
    "        # Get the index\n",
    "        max_truth_index_ = all_truth_labels.index(max_truth_)\n",
    "        #print( 'predicted index: %s, truth index: %s' % (max_pred_index_, max_truth_index_) )\n",
    "        return max_pred_index_, max_truth_index_\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deb67b85",
   "metadata": {},
   "source": [
    "### Create dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "6f324502",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features batch shape: torch.Size([500, 42]) \n",
      "Labels batch shape: torch.Size([500]) \n",
      "sig/bkg class ratio:  5.944444444444445\n"
     ]
    }
   ],
   "source": [
    "# Create datasets\n",
    "transformed_df = transformed_df[transformed_df['label_valid']==1]\n",
    "train_df, test_df = train_test_split(transformed_df, test_size=0.2, shuffle=False)\n",
    "test_df, val_df = train_test_split(test_df, test_size=0.5, shuffle=False)\n",
    "\n",
    "train_dataset = custom_train_dataset(train_df, input_columns_, 'label_pair', device=device)\n",
    "test_dataset  = custom_train_dataset(test_df, input_columns_, 'label_pair', device=device)\n",
    "valid_dataset = custom_train_dataset(val_df, input_columns_, 'label_pair', device=device)\n",
    "\n",
    "# DataLoaders for train datasets\n",
    "training_data_loader = DataLoader(train_dataset, batch_size=batchsize, shuffle=True)\n",
    "testing_data_loader = DataLoader(test_dataset, batch_size=batchsize, shuffle=False)\n",
    "\n",
    "# Test dataLoaders by loading batches of features and labels\n",
    "train_features, train_labels = next(iter(training_data_loader))\n",
    "print(f\"Features batch shape: {train_features.size()} \")\n",
    "print(f\"Labels batch shape: {train_labels.size()} \")\n",
    "\n",
    "# Class weights\n",
    "# Be careful using class weights:\n",
    "#       - Too large and they can cause instability in the training such that the algorithm doesnt learn\n",
    "#       - Too small and if you have class imbalance, class(es) can be ignored to obtain high accuracy\n",
    "n_sig = [x for x in train_labels if x == 1]\n",
    "n_bkg = [x for x in train_labels if x == 0]\n",
    "class_ratio = len(n_bkg)/len(n_sig)\n",
    "print('sig/bkg class ratio: ', class_ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "30668955",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NeuralNetwork(\n",
      "  (linear_relu_stack): Sequential(\n",
      "    (0): Flatten(start_dim=1, end_dim=-1)\n",
      "    (1): Linear(in_features=42, out_features=24, bias=True)\n",
      "    (2): ReLU()\n",
      "    (3): Linear(in_features=24, out_features=12, bias=True)\n",
      "    (4): ReLU()\n",
      "    (5): Linear(in_features=12, out_features=8, bias=True)\n",
      "    (6): ReLU()\n",
      "    (7): Linear(in_features=8, out_features=4, bias=True)\n",
      "    (8): ReLU()\n",
      "    (9): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fdff3b85c80f445baf0494f0f8381053",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/450 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "loss_function = nn.BCEWithLogitsLoss(pos_weight=torch.tensor(class_ratio))\n",
    "#loss_function = nn.BCEWithLogitsLoss()\n",
    "\n",
    "model = NeuralNetwork(len(input_columns_)).to(device)\n",
    "print(model)\n",
    "\n",
    "# Initialsed optimiser with models parameters\n",
    "# n.b. must call parameters method on model when initialising optimiser\n",
    "optimizer = torch.optim.NAdam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# Looping over entire dataset\n",
    "train_losses = []\n",
    "test_losses = []\n",
    "iters = 0\n",
    "\n",
    "fig, ax = plt.subplots(ncols=1, figsize=(4,4))\n",
    "import tqdm\n",
    "epochs = tqdm.notebook.trange(n_epochs)\n",
    "from IPython import display\n",
    "dh = display.display(fig, display_id=True)\n",
    "\n",
    "for epoch in epochs:\n",
    "    loss_ , model_ = train_loop(training_data_loader, model, loss_function, optimizer)\n",
    "    test_loss_ = test_loop(testing_data_loader, model, loss_function)\n",
    "    # Calculate the average loss over the epoch\n",
    "    av_training_loss = loss_/len(training_data_loader.sampler)\n",
    "    av_testing_loss = test_loss_/len(testing_data_loader.sampler)\n",
    "    epochs.set_description('Average Loss: {:5f}(Train) {:5f}(Test)'.format(av_training_loss, av_testing_loss))\n",
    "    train_losses.append(av_training_loss)\n",
    "    test_losses.append(av_testing_loss)\n",
    "\n",
    "    model_outdir_name = 'model_'+str(learning_rate)+'_'+str(batchsize)+'_'+str(n_epochs)\n",
    "    if not os.path.isdir(model_outdir_name):\n",
    "            print('Making model directory: ', model_outdir_name)\n",
    "            os.makedirs(model_outdir_name)\n",
    "    model_save_ = os.path.join(model_outdir_name,'saved_model.pt')\n",
    "    torch.save(model_.state_dict(), model_save_)\n",
    "\n",
    "    fig, ax = plt.subplots(ncols=1, figsize=(4,4))\n",
    "    plt.title('')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.yscale('log')\n",
    "    plt.plot(train_losses, label='training')\n",
    "    plt.plot(test_losses, label='testing')\n",
    "    plt.legend(loc='upper right')\n",
    "    dh.update(fig)\n",
    "    plt.close(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "909f482b",
   "metadata": {},
   "source": [
    "## Application (Validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "2bb904f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation on  cuda\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument mat1 in method wrapper_addmm)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_408/3359382769.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0mval_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcustom_train_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgroups_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_group\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevnum\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_columns_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'label_pair'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0mval_data_loader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m     \u001b[0mmax_pred_idx\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mcorr_idx_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meval_loop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_data_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_function\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m     \u001b[0mlabel_high_pt_sel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpT_rank_sel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgroups_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_group\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevnum\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_408/4105042074.py\u001b[0m in \u001b[0;36meval_loop\u001b[0;34m(dataloader, model, loss_fn)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdataloader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m             \u001b[0;31m# make prediction using model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m             \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# required to ensure same dimensions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mall_truth_labels\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/cvmfs/sft.cern.ch/lcg/views/LCG_103cuda/x86_64-centos7-gcc11-opt/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1195\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_408/931201113.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0;31m# Passing input data to model automatically executes models forward method\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m         \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear_relu_stack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mlogits\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/cvmfs/sft.cern.ch/lcg/views/LCG_103cuda/x86_64-centos7-gcc11-opt/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1195\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/cvmfs/sft.cern.ch/lcg/views/LCG_103cuda/x86_64-centos7-gcc11-opt/lib/python3.9/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    202\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 204\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    205\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/cvmfs/sft.cern.ch/lcg/views/LCG_103cuda/x86_64-centos7-gcc11-opt/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1195\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/cvmfs/sft.cern.ch/lcg/views/LCG_103cuda/x86_64-centos7-gcc11-opt/lib/python3.9/site-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument mat1 in method wrapper_addmm)"
     ]
    }
   ],
   "source": [
    "print('Evaluation on ', device)\n",
    "groups_ = val_df.groupby('Entry')\n",
    "num_corr_ptSel = 0\n",
    "num_corr = 0\n",
    "total_ = 0\n",
    "\n",
    "def pT_rank_sel(test_dataset):\n",
    "    sum_pt_ = -100\n",
    "    for row in test_dataset.index:\n",
    "        if test_dataset['bmatched_jet_pt'][row] < test_dataset['lmatched_jet_pt'][row]: continue\n",
    "        if test_dataset['bmatched_jet_pt'][row] + test_dataset['lmatched_jet_pt'][row] > sum_pt_:\n",
    "            sum_pt_ = test_dataset['bmatched_jet_pt'][row] + test_dataset['lmatched_jet_pt'][row]\n",
    "            label_pT_high = test_dataset['label_pair'][row]\n",
    "\n",
    "    return label_pT_high\n",
    "\n",
    "for evnum in groups_.groups.keys():\n",
    "    val_dataset = custom_train_dataset(groups_.get_group(evnum), input_columns_, 'label_pair', device=device)\n",
    "    val_data_loader = DataLoader(val_dataset, batch_size=len(val_dataset), shuffle=False)\n",
    "    max_pred_idx , corr_idx_ = eval_loop(val_data_loader, model, loss_function)\n",
    "    label_high_pt_sel = pT_rank_sel(groups_.get_group(evnum))\n",
    "\n",
    "    total_ += 1\n",
    "    if label_high_pt_sel == 1:\n",
    "        num_corr_ptSel+=1\n",
    "    if max_pred_idx == corr_idx_:\n",
    "        num_corr+=1\n",
    "percent_corr_ptSel = (num_corr_ptSel/total_)*100\n",
    "percent_corr = (num_corr/total_)*100\n",
    "print(f'{num_corr}/{total_} ({percent_corr:.3} percent) events correctly assigned by algo')\n",
    "print(f'{num_corr_ptSel}/{total_} ({percent_corr_ptSel:.3} percent) events correctly assigned by selecting high-pt pair')\n",
    "with open(os.path.join(model_outdir_name,'results.txt'), 'w') as f:\n",
    "        lines =[f'{num_corr}/{total_} ({percent_corr:.3} percent) events correctly assigned by algo', f'{num_corr_ptSel}/{total_} ({percent_corr_ptSel:.3} percent) events correctly assigned by selecting high-pt pair']\n",
    "        f.write('\\n'.join(lines))\n",
    "print('FIN!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "48ee7f12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NeuralNetwork(\n",
       "  (linear_relu_stack): Sequential(\n",
       "    (0): Flatten(start_dim=1, end_dim=-1)\n",
       "    (1): Linear(in_features=42, out_features=24, bias=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=24, out_features=12, bias=True)\n",
       "    (4): ReLU()\n",
       "    (5): Linear(in_features=12, out_features=8, bias=True)\n",
       "    (6): ReLU()\n",
       "    (7): Linear(in_features=8, out_features=4, bias=True)\n",
       "    (8): ReLU()\n",
       "    (9): Linear(in_features=4, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load DNN \n",
    "model = NeuralNetwork(len(input_columns_))\n",
    "model.load_state_dict(torch.load('model_1e-05_500_450/saved_model.pt'))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "9578966e",
   "metadata": {},
   "outputs": [],
   "source": [
    "source_combs = val_df[input_columns_].values\n",
    "X_input      = torch.tensor(source_combs, dtype=torch.float32)\n",
    "predicted    = torch.sigmoid(model(X_input)).detach().numpy()\n",
    "predicted    = np.array(predicted.reshape(len(predicted)))\n",
    "val_df_copy  = val_df\n",
    "val_df_copy.insert(1, \"predicted\", predicted)\n",
    "idx = val_df_copy.groupby(['Entry'])['predicted'].transform(max) == val_df_copy['predicted']\n",
    "df = val_df_copy[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "afeb6adb",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_1 = val_df.groupby(['Entry'])['bmatched_jet_index'].transform(min) == val_df['bmatched_jet_index']\n",
    "df1 = val_df[idx_1]\n",
    "idx_2 = df1.groupby(['Entry'])['lmatched_jet_index'].transform(min) == df1['lmatched_jet_index']\n",
    "df2 = df1[idx_2]\n",
    "idx_3 = df2.groupby(['Entry'])['jet3_index'].transform(min) == df2['jet3_index']\n",
    "df3 = df2[idx_3]\n",
    "idx_4 = df3.groupby(['Entry'])['jet4_index'].transform(min) == df3['jet4_index']\n",
    "df_order = df3[idx_4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "330e1265",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_well_match = df[df['label_valid'] == 1]\n",
    "df_bad_match  = df[df['label_valid'] == 0]\n",
    "df_well_match_order = df_order[df_order['label_valid'] == 1]\n",
    "df_bad_match_order  = df_order[df_order['label_valid'] == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "0d31adcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ratio of well matching:  1.0\n",
      "----- well match (order) -----\n",
      "accuracy: 0.2363\n",
      "accuracy(pt order): 0.1465\n",
      "----- well match (pair) -----\n",
      "accuracy: 0.4604\n",
      "accuracy(pt order): 0.3966\n"
     ]
    }
   ],
   "source": [
    "print(\"ratio of well matching: \", len(df_well_match)/len(df))\n",
    "print(\"----- well match (order) -----\")\n",
    "print(\"accuracy: %.4f\"%(df_well_match['label'].sum()/len(df_well_match)))\n",
    "print(\"accuracy(pt order): %.4f\"%(df_well_match_order['label'].sum()/len(df_well_match_order)))\n",
    "print(\"----- well match (pair) -----\")\n",
    "print(\"accuracy: %.4f\"%(df_well_match['label_pair'].sum()/len(df_well_match)))\n",
    "print(\"accuracy(pt order): %.4f\"%(df_well_match_order['label_pair'].sum()/len(df_well_match_order)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5646cbe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def invariant_mass(pt1: pd.Series,\n",
    "                   eta1: pd.Series,\n",
    "                   phi1: pd.Series,\n",
    "                   mass1: pd.Series,\n",
    "                   pt2: pd.Series,\n",
    "                   eta2: pd.Series,\n",
    "                   phi2: pd.Series,\n",
    "                   mass2: pd.Series) -> pd.Series:\n",
    "    v1 = vector.obj(pt=pt1, eta=eta1, phi=phi1, mass=mass1)\n",
    "    v2 = vector.obj(pt=pt2, eta=eta2, phi=phi2, mass=mass2)\n",
    "\n",
    "    return (v1+v2).mass\n",
    "def pt_sum(pt1: pd.Series,\n",
    "           pt2: pd.Series) -> pd.Series:\n",
    "    return pt1 + pt2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "91e14f5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "inv_mass = df_well_match.apply(lambda row: invariant_mass(row[\"bmatched_jet_pt\"],\n",
    "                                                          row[\"bmatched_jet_eta\"], \n",
    "                                                          row[\"bmatched_jet_phi\"],\n",
    "                                                          row[\"bmatched_jet_mass\"],\n",
    "                                                          row[\"lmatched_jet_pt\"],\n",
    "                                                          row[\"lmatched_jet_eta\"],\n",
    "                                                          row[\"lmatched_jet_phi\"],\n",
    "                                                          row[\"lmatched_jet_mass\"]), axis =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ee9d374",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
